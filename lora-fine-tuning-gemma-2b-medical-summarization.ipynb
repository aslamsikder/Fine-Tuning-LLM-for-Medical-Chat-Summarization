{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Cell 1: Project Setup and Installation**\n\nThis first step is crucial for setting up our environment. We will install all the necessary Python libraries. The most important library here is unsloth, which is specifically designed to make fine-tuning large language models (LLMs) significantly faster and more memory-efficient. This library is the key to making this project feasible on a free, resource-constrained GPU (like a T4 in Google Colab / T4*2 in Kaggle) which typically has VRAM limitations that would prevent standard fine-tuning. We also install trl for its specialized training tools, peft for parameter-efficient fine-tuning, and other standard libraries from the Hugging Face ecosystem.","metadata":{}},{"cell_type":"code","source":"# Cell 1\n# Install required libraries\n# We use unsloth for memory-efficient and faster fine-tuning of LLMs.\n!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\" -q\n!pip install \"trl<0.9.0\" peft accelerate bitsandbytes -q\n!pip install datasets evaluate bert_score -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T03:10:17.020318Z","iopub.execute_input":"2025-10-26T03:10:17.020573Z","iopub.status.idle":"2025-10-26T03:12:34.651557Z","shell.execute_reply.started":"2025-10-26T03:10:17.020545Z","shell.execute_reply":"2025-10-26T03:12:34.650498Z"}},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m270.4/270.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nunsloth-zoo 2025.10.10 requires trl!=0.19.0,<=0.23.0,>=0.18.2, but you have trl 0.8.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**Cell 2: Hugging Face Authentication**\n\nTo download the model or dataset we need to authenticate with Hugging Face. This step uses the login function to securely connect to your Hugging Face account. You will need to generate an access token with \"write\" permissions from your Hugging Face account settings and save it as a secret in your environment (in Colab/Kaggle, this is done via the \"Secrets\" tab). This ensures your credentials are not exposed in the code.","metadata":{}},{"cell_type":"code","source":"# Cell 2\n# Hugging Face login & Git LFS setup (for Kaggle)\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\n# Authenticate with Hugging Face to access the Llama 3 model\n# Ensure you have saved your Hugging Face token as 'HF_TOKEN' in Colab secrets\ntry:\n    secret_label = \"HF_TOKEN\"  # This should match the name of your secret in Kaggle\n    hf_token = UserSecretsClient().get_secret(secret_label)\n    \n    # Log in securely to Hugging Face\n    login(token=hf_token)\n    print(\"Successfully logged into Hugging Face.\")\nexcept Exception as e:\n    print(f\"Could not log in. Please ensure 'HF_TOKEN' is set in Colab secrets. Error: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T03:12:54.351805Z","iopub.execute_input":"2025-10-26T03:12:54.352589Z","iopub.status.idle":"2025-10-26T03:12:54.995793Z","shell.execute_reply.started":"2025-10-26T03:12:54.352545Z","shell.execute_reply":"2025-10-26T03:12:54.994838Z"}},"outputs":[{"name":"stdout","text":"Successfully logged into Hugging Face.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"**Cell 3: Load Model and Tokenizer**\n\nHere, we load the Gemma 2b model and its corresponding tokenizer. We use unsloth's **FastLanguageModel** class, which is a highly optimized wrapper around the standard Hugging Face model class.\n\nKey parameters used:\n*   model_name = \"unsloth/gemma-2b-it-bnb-4bit\": We use a version of Llama 3 that has been pre-quantized to 4-bit precision and optimized for Unsloth. This dramatically reduces the memory required to load the model.\n*   load_in_4bit = True: This argument explicitly tells the model to load the weights in 4-bit precision, which is the core of our memory-saving strategy.\n*   max_seq_length = 2048: We set a maximum sequence length to balance context understanding with memory constraints.\n\nThis cell makes the impossible possible: loading a billion-parameter model into a GPU with less than 8GB of VRAM.","metadata":{}},{"cell_type":"code","source":"# Cell 3\nimport torch\nfrom unsloth import FastLanguageModel\n\n# Define model loading parameters\nmax_seq_length = 2048  # Maximum sequence length\ndtype = None           # Unsloth will automatically choose the best dtype (bf16/fp16)\nload_in_4bit = True    # Load in 4-bit quantized precision for memory efficiency\n\nprint(\"Loading Gemma 2B model and tokenizer with Unsloth...\")\n\n# Load the pre-quantized Gemma 2B instruction-tuned model\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/gemma-2b-it-bnb-4bit\",  # Instruction-tuned, 4-bit version\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n    trust_remote_code=True,  # Necessary for custom model implementations\n)\n\n# Verification\nprint(\"Model and tokenizer loaded successfully.\")\nprint(f\"Model Type: {model.config.model_type}\")\nprint(f\"Max Seq Length: {max_seq_length}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T03:13:00.592281Z","iopub.execute_input":"2025-10-26T03:13:00.592932Z","iopub.status.idle":"2025-10-26T03:14:24.569584Z","shell.execute_reply.started":"2025-10-26T03:13:00.592907Z","shell.execute_reply":"2025-10-26T03:14:24.568649Z"}},"outputs":[{"name":"stdout","text":"ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-10-26 03:13:13.874806: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761448394.289517      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761448394.411408      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ü¶• Unsloth Zoo will now patch everything to make training faster!\nLoading Gemma 2B model and tokenizer with Unsloth...\nUnsloth: WARNING `trust_remote_code` is True.\nAre you certain you want to do remote code execution?\n==((====))==  Unsloth 2025.10.9: Fast Gemma patching. Transformers: 4.56.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.07G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08bb7be7a7c644f9acc581af1e2042cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/154 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f66138722ade4ea2b838ea2eb732b114"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87e3817107f04d918ea7ab35cd5cfa9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7afe7196e7de4dac8415c1c879fe7a47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6977ebf05ff0439e97e9da19afaf80a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca4e7e5310134e09aadd831a9bd02a12"}},"metadata":{}},{"name":"stdout","text":"Model and tokenizer loaded successfully.\nModel Type: gemma\nMax Seq Length: 2048\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"**Cell 4: Load and Explore the Dataset**\n\nWe load our medical dialogue dataset directly from the Hugging Face Hub. The dataset is conveniently split into train, validation, and test sets. We will use the datasets library for this. After loading, we'll inspect the data to understand its structure, confirming the presence of the dialogue and soap columns which will serve as our input and target, respectively.","metadata":{}},{"cell_type":"code","source":"# Cell 4\nfrom datasets import load_dataset\n\n# Load the medical dialogue dataset from Hugging Face\ndataset_name = \"omi-health/medical-dialogue-to-soap-summary\"\n\nprint(f\"Loading dataset: {dataset_name} ...\")\n\n# Load train, validation, and test splits\ntrain_dataset = load_dataset(dataset_name, split=\"train\")\nvalidation_dataset = load_dataset(dataset_name, split=\"validation\")\ntest_dataset = load_dataset(dataset_name, split=\"test\")\n\n# Display dataset information\nprint(\"\\nDataset loaded successfully!\")\nprint(f\"Train samples: {len(train_dataset)}\")\nprint(f\"Validation samples: {len(validation_dataset)}\")\nprint(f\"Test samples: {len(test_dataset)}\")\n\n# Display column names\nprint(\"\\nAvailable columns:\", train_dataset.column_names)\n\n# Show one formatted example (to verify fields before preprocessing)\nprint(\"\\nExample sample from training set:\")\nprint(train_dataset[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T03:14:35.513161Z","iopub.execute_input":"2025-10-26T03:14:35.513465Z","iopub.status.idle":"2025-10-26T03:14:41.039951Z","shell.execute_reply.started":"2025-10-26T03:14:35.513444Z","shell.execute_reply":"2025-10-26T03:14:41.039190Z"}},"outputs":[{"name":"stdout","text":"üì¶ Loading dataset: omi-health/medical-dialogue-to-soap-summary ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6574f899899a47d9bee8b60932cf7ee5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.json:   0%|          | 0.00/154M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bc4e0284193463186c60d0b99434743"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1a29dfae9e04a7ab32e67035d18a95f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bad48c304034b70b38860b2955e7ddb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/9250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"235deb1ba9d9458d98379e9dc9664e3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"186bb9d121294abbaeaa6fa1627494e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cca0586dba8643cf85c6c82f5c160bad"}},"metadata":{}},{"name":"stdout","text":"\nDataset loaded successfully!\nTrain samples: 9250\nValidation samples: 500\nTest samples: 250\n\nAvailable columns: ['dialogue', 'soap', 'prompt', 'messages', 'messages_nosystem']\n\nExample sample from training set:\n{'dialogue': \"Doctor: Hello, how can I help you today?\\nPatient: My son has been having some issues with speech and development. He's 13 years old now.\\nDoctor: I see. Can you tell me more about his symptoms? Does he have any issues with muscle tone or hypotonia?\\nPatient: No, he doesn't have hypotonia. But he has mild to moderate speech and developmental delay, and he's been diagnosed with attention deficit disorder.\\nDoctor: Thank you for sharing that information. We'll run some tests, including an MRI, to get a better understanding of your son's condition. \\n(After the tests)\\nDoctor: The MRI results are in, and I'm glad to say that there are no structural brain anomalies. However, I did notice some physical characteristics. Does your son have any facial features like retrognathia, mild hypertelorism, or a slightly elongated philtrum and thin upper lip?\\nPatient: Yes, he has all of those features. His hands are also broad and short. And his feet have mild syndactyly of the second and third toe, with a sandal gap in both feet.\\nDoctor: Thank you for confirming that. We also conducted Whole Exome Sequencing (WES) analyses, and we found a de novo frameshift variant in his genetic makeup. Specifically, it's Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)). This leads to a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nPatient: What does that mean for my son?\\nDoctor: This genetic variant may be contributing to your son's speech, developmental delay, and attention deficit disorder. It's important that we continue monitoring his progress and provide appropriate support for his development.\\nPatient: What should we do for follow-up?\\nDoctor: Regular visits with a speech and language therapist, an occupational therapist, and a psychologist can help address your son's developmental and attention deficit disorder needs. I will also recommend regular check-ups with me to monitor his growth and overall health.\\nPatient: Thank you, doctor. We will follow your recommendations and keep an eye on his progress.\", 'soap': \"S: The patient's mother reports that her 13-year-old son has mild to moderate speech and developmental delays and has been diagnosed with attention deficit disorder. She denies any issues with muscle tone or hypotonia. The patient also exhibits certain physical characteristics, including retrognathia, mild hypertelorism, an elongated philtrum, thin upper lip, broad and short hands, mild syndactyly of the second and third toes, and a sandal gap in both feet.\\nO: An MRI of the brain showed no structural anomalies. Whole Exome Sequencing (WES) revealed a de novo frameshift variant Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)), indicating a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nA: The primary diagnosis is a genetic disorder associated with the identified frameshift mutation, which likely contributes to the patient's speech and developmental delays and attention deficit disorder. The physical characteristics and genetic findings suggest a specific syndrome, which needs further correlation with clinical findings and genetic counseling.\\nP: The management plan includes regular follow-up visits with a speech and language therapist, an occupational therapist, and a psychologist to support the patient's developmental needs and address his attention deficit disorder. Regular medical check-ups will monitor his growth and overall health. Genetic counseling for the family is also recommended to discuss the implications of the genetic findings and potential familial inheritance.\", 'prompt': \"Create a Medical SOAP note summary from the dialogue, following these guidelines:\\n    S (Subjective): Summarize the patient's reported symptoms, including chief complaint and relevant history. Rely on the patient's statements as the primary source and ensure standardized terminology.\\n    O (Objective): Highlight critical findings such as vital signs, lab results, and imaging, emphasizing important details like the side of the body affected and specific dosages. Include normal ranges where relevant.\\n    A (Assessment): Offer a concise assessment combining subjective and objective data. State the primary diagnosis and any differential diagnoses, noting potential complications and the prognostic outlook.\\n    P (Plan): Outline the management plan, covering medication, diet, consultations, and education. Ensure to mention necessary referrals to other specialties and address compliance challenges.\\n    Considerations: Compile the report based solely on the transcript provided. Maintain confidentiality and document sensitively. Use concise medical jargon and abbreviations for effective doctor communication.\\n    Please format the summary in a clean, simple list format without using markdown or bullet points. Use 'S:', 'O:', 'A:', 'P:' directly followed by the text. Avoid any styling or special characters.\", 'messages': [{'role': 'system', 'content': 'You are an expert medical professor assisting in the creation of medically accurate SOAP summaries. Please ensure the response follows the structured format: S:, O:, A:, P: without using markdown or special formatting.'}, {'role': 'user', 'content': \"Create a Medical SOAP note summary from the dialogue, following these guidelines:\\n    S (Subjective): Summarize the patient's reported symptoms, including chief complaint and relevant history. Rely on the patient's statements as the primary source and ensure standardized terminology.\\n    O (Objective): Highlight critical findings such as vital signs, lab results, and imaging, emphasizing important details like the side of the body affected and specific dosages. Include normal ranges where relevant.\\n    A (Assessment): Offer a concise assessment combining subjective and objective data. State the primary diagnosis and any differential diagnoses, noting potential complications and the prognostic outlook.\\n    P (Plan): Outline the management plan, covering medication, diet, consultations, and education. Ensure to mention necessary referrals to other specialties and address compliance challenges.\\n    Considerations: Compile the report based solely on the transcript provided. Maintain confidentiality and document sensitively. Use concise medical jargon and abbreviations for effective doctor communication.\\n    Please format the summary in a clean, simple list format without using markdown or bullet points. Use 'S:', 'O:', 'A:', 'P:' directly followed by the text. Avoid any styling or special characters. ### Dialogue:\\nDoctor: Hello, how can I help you today?\\nPatient: My son has been having some issues with speech and development. He's 13 years old now.\\nDoctor: I see. Can you tell me more about his symptoms? Does he have any issues with muscle tone or hypotonia?\\nPatient: No, he doesn't have hypotonia. But he has mild to moderate speech and developmental delay, and he's been diagnosed with attention deficit disorder.\\nDoctor: Thank you for sharing that information. We'll run some tests, including an MRI, to get a better understanding of your son's condition. \\n(After the tests)\\nDoctor: The MRI results are in, and I'm glad to say that there are no structural brain anomalies. However, I did notice some physical characteristics. Does your son have any facial features like retrognathia, mild hypertelorism, or a slightly elongated philtrum and thin upper lip?\\nPatient: Yes, he has all of those features. His hands are also broad and short. And his feet have mild syndactyly of the second and third toe, with a sandal gap in both feet.\\nDoctor: Thank you for confirming that. We also conducted Whole Exome Sequencing (WES) analyses, and we found a de novo frameshift variant in his genetic makeup. Specifically, it's Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)). This leads to a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nPatient: What does that mean for my son?\\nDoctor: This genetic variant may be contributing to your son's speech, developmental delay, and attention deficit disorder. It's important that we continue monitoring his progress and provide appropriate support for his development.\\nPatient: What should we do for follow-up?\\nDoctor: Regular visits with a speech and language therapist, an occupational therapist, and a psychologist can help address your son's developmental and attention deficit disorder needs. I will also recommend regular check-ups with me to monitor his growth and overall health.\\nPatient: Thank you, doctor. We will follow your recommendations and keep an eye on his progress.\"}, {'role': 'assistant', 'content': \"S: The patient's mother reports that her 13-year-old son has mild to moderate speech and developmental delays and has been diagnosed with attention deficit disorder. She denies any issues with muscle tone or hypotonia. The patient also exhibits certain physical characteristics, including retrognathia, mild hypertelorism, an elongated philtrum, thin upper lip, broad and short hands, mild syndactyly of the second and third toes, and a sandal gap in both feet.\\nO: An MRI of the brain showed no structural anomalies. Whole Exome Sequencing (WES) revealed a de novo frameshift variant Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)), indicating a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nA: The primary diagnosis is a genetic disorder associated with the identified frameshift mutation, which likely contributes to the patient's speech and developmental delays and attention deficit disorder. The physical characteristics and genetic findings suggest a specific syndrome, which needs further correlation with clinical findings and genetic counseling.\\nP: The management plan includes regular follow-up visits with a speech and language therapist, an occupational therapist, and a psychologist to support the patient's developmental needs and address his attention deficit disorder. Regular medical check-ups will monitor his growth and overall health. Genetic counseling for the family is also recommended to discuss the implications of the genetic findings and potential familial inheritance.\"}], 'messages_nosystem': [{'role': 'user', 'content': \"You are an expert medical professor assisting in the creation of medically accurate SOAP summaries. Please ensure the response follows the structured format: S:, O:, A:, P: without using markdown or special formatting. Create a Medical SOAP note summary from the dialogue, following these guidelines:\\n    S (Subjective): Summarize the patient's reported symptoms, including chief complaint and relevant history. Rely on the patient's statements as the primary source and ensure standardized terminology.\\n    O (Objective): Highlight critical findings such as vital signs, lab results, and imaging, emphasizing important details like the side of the body affected and specific dosages. Include normal ranges where relevant.\\n    A (Assessment): Offer a concise assessment combining subjective and objective data. State the primary diagnosis and any differential diagnoses, noting potential complications and the prognostic outlook.\\n    P (Plan): Outline the management plan, covering medication, diet, consultations, and education. Ensure to mention necessary referrals to other specialties and address compliance challenges.\\n    Considerations: Compile the report based solely on the transcript provided. Maintain confidentiality and document sensitively. Use concise medical jargon and abbreviations for effective doctor communication.\\n    Please format the summary in a clean, simple list format without using markdown or bullet points. Use 'S:', 'O:', 'A:', 'P:' directly followed by the text. Avoid any styling or special characters. ### Dialogue:\\nDoctor: Hello, how can I help you today?\\nPatient: My son has been having some issues with speech and development. He's 13 years old now.\\nDoctor: I see. Can you tell me more about his symptoms? Does he have any issues with muscle tone or hypotonia?\\nPatient: No, he doesn't have hypotonia. But he has mild to moderate speech and developmental delay, and he's been diagnosed with attention deficit disorder.\\nDoctor: Thank you for sharing that information. We'll run some tests, including an MRI, to get a better understanding of your son's condition. \\n(After the tests)\\nDoctor: The MRI results are in, and I'm glad to say that there are no structural brain anomalies. However, I did notice some physical characteristics. Does your son have any facial features like retrognathia, mild hypertelorism, or a slightly elongated philtrum and thin upper lip?\\nPatient: Yes, he has all of those features. His hands are also broad and short. And his feet have mild syndactyly of the second and third toe, with a sandal gap in both feet.\\nDoctor: Thank you for confirming that. We also conducted Whole Exome Sequencing (WES) analyses, and we found a de novo frameshift variant in his genetic makeup. Specifically, it's Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)). This leads to a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nPatient: What does that mean for my son?\\nDoctor: This genetic variant may be contributing to your son's speech, developmental delay, and attention deficit disorder. It's important that we continue monitoring his progress and provide appropriate support for his development.\\nPatient: What should we do for follow-up?\\nDoctor: Regular visits with a speech and language therapist, an occupational therapist, and a psychologist can help address your son's developmental and attention deficit disorder needs. I will also recommend regular check-ups with me to monitor his growth and overall health.\\nPatient: Thank you, doctor. We will follow your recommendations and keep an eye on his progress.\"}, {'role': 'assistant', 'content': \"S: The patient's mother reports that her 13-year-old son has mild to moderate speech and developmental delays and has been diagnosed with attention deficit disorder. She denies any issues with muscle tone or hypotonia. The patient also exhibits certain physical characteristics, including retrognathia, mild hypertelorism, an elongated philtrum, thin upper lip, broad and short hands, mild syndactyly of the second and third toes, and a sandal gap in both feet.\\nO: An MRI of the brain showed no structural anomalies. Whole Exome Sequencing (WES) revealed a de novo frameshift variant Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)), indicating a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nA: The primary diagnosis is a genetic disorder associated with the identified frameshift mutation, which likely contributes to the patient's speech and developmental delays and attention deficit disorder. The physical characteristics and genetic findings suggest a specific syndrome, which needs further correlation with clinical findings and genetic counseling.\\nP: The management plan includes regular follow-up visits with a speech and language therapist, an occupational therapist, and a psychologist to support the patient's developmental needs and address his attention deficit disorder. Regular medical check-ups will monitor his growth and overall health. Genetic counseling for the family is also recommended to discuss the implications of the genetic findings and potential familial inheritance.\"}]}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**Cell 5: Data Preprocessing and Prompt Formatting**\n\nInstruction-tuned models like Gemma 2B perform best when the input data is formatted as a clear instruction. We use the official Gemma 2B chat template to structure our data in a conversational format that distinguishes between the user‚Äôs request and the model‚Äôs response. Each example is converted into a prompt where the user instructs the model to summarize a given medical dialogue into a SOAP note, and the model provides the corresponding summary. This ensures that the fine-tuned model learns to follow natural instructions effectively. We define a function format_chat_template to apply this transformation and then use the .map() method to process all splits of our dataset efficiently for training.","metadata":{}},{"cell_type":"code","source":"# Cell 5\n\ndef format_chat_template(row):\n    # Gemma 2B expects simple role-based text prompts\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": f\"Summarize the following medical dialogue into a SOAP note:\\n\\n{row['dialogue']}\"\n        },\n        {\n            \"role\": \"model\",\n            \"content\": f\"{row['soap']}\"\n        }\n    ]\n    \n    # Define the official Gemma chat template\n    tokenizer.chat_template = (\n        \"{% for message in messages %}\"\n        \"{% if message['role'] == 'user' %}\"\n        \"{{ '<bos><start_of_turn>user\\n' + message['content'] + '<end_of_turn>\\n' }}\"\n        \"{% elif message['role'] == 'model' %}\"\n        \"{{ '<start_of_turn>model\\n' + message['content'] + '<end_of_turn>' }}\"\n        \"{% endif %}\"\n        \"{% endfor %}\"\n    )\n    \n    # Apply template without tokenizing\n    return {\"text\": tokenizer.apply_chat_template(messages, tokenize=False)}\n\n# Apply to all splits\ntrain_dataset_formatted = train_dataset.map(format_chat_template)\nvalidation_dataset_formatted = validation_dataset.map(format_chat_template)\ntest_dataset_formatted = test_dataset.map(format_chat_template)\n\n# Display a formatted example\nprint(\"\\nFormatted prompt example:\")\nprint(train_dataset_formatted[\"text\"][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T03:15:11.961611Z","iopub.execute_input":"2025-10-26T03:15:11.961911Z","iopub.status.idle":"2025-10-26T03:15:15.522990Z","shell.execute_reply.started":"2025-10-26T03:15:11.961888Z","shell.execute_reply":"2025-10-26T03:15:15.522111Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c37ba49f3914fe69b161e6785ba8c53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c64c4d92d0b48b4919f796b0fbebbe8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"480de050a88c482b804a2f0b61271f95"}},"metadata":{}},{"name":"stdout","text":"\n‚úÖ Formatted prompt example:\n<bos><start_of_turn>user\nSummarize the following medical dialogue into a SOAP note:\n\nDoctor: Hello, how can I help you today?\nPatient: My son has been having some issues with speech and development. He's 13 years old now.\nDoctor: I see. Can you tell me more about his symptoms? Does he have any issues with muscle tone or hypotonia?\nPatient: No, he doesn't have hypotonia. But he has mild to moderate speech and developmental delay, and he's been diagnosed with attention deficit disorder.\nDoctor: Thank you for sharing that information. We'll run some tests, including an MRI, to get a better understanding of your son's condition. \n(After the tests)\nDoctor: The MRI results are in, and I'm glad to say that there are no structural brain anomalies. However, I did notice some physical characteristics. Does your son have any facial features like retrognathia, mild hypertelorism, or a slightly elongated philtrum and thin upper lip?\nPatient: Yes, he has all of those features. His hands are also broad and short. And his feet have mild syndactyly of the second and third toe, with a sandal gap in both feet.\nDoctor: Thank you for confirming that. We also conducted Whole Exome Sequencing (WES) analyses, and we found a de novo frameshift variant in his genetic makeup. Specifically, it's Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)). This leads to a premature termination codon located more than 400 codons upstream of the canonical termination codon.\nPatient: What does that mean for my son?\nDoctor: This genetic variant may be contributing to your son's speech, developmental delay, and attention deficit disorder. It's important that we continue monitoring his progress and provide appropriate support for his development.\nPatient: What should we do for follow-up?\nDoctor: Regular visits with a speech and language therapist, an occupational therapist, and a psychologist can help address your son's developmental and attention deficit disorder needs. I will also recommend regular check-ups with me to monitor his growth and overall health.\nPatient: Thank you, doctor. We will follow your recommendations and keep an eye on his progress.<end_of_turn>\n<start_of_turn>model\nS: The patient's mother reports that her 13-year-old son has mild to moderate speech and developmental delays and has been diagnosed with attention deficit disorder. She denies any issues with muscle tone or hypotonia. The patient also exhibits certain physical characteristics, including retrognathia, mild hypertelorism, an elongated philtrum, thin upper lip, broad and short hands, mild syndactyly of the second and third toes, and a sandal gap in both feet.\nO: An MRI of the brain showed no structural anomalies. Whole Exome Sequencing (WES) revealed a de novo frameshift variant Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)), indicating a premature termination codon located more than 400 codons upstream of the canonical termination codon.\nA: The primary diagnosis is a genetic disorder associated with the identified frameshift mutation, which likely contributes to the patient's speech and developmental delays and attention deficit disorder. The physical characteristics and genetic findings suggest a specific syndrome, which needs further correlation with clinical findings and genetic counseling.\nP: The management plan includes regular follow-up visits with a speech and language therapist, an occupational therapist, and a psychologist to support the patient's developmental needs and address his attention deficit disorder. Regular medical check-ups will monitor his growth and overall health. Genetic counseling for the family is also recommended to discuss the implications of the genetic findings and potential familial inheritance.<end_of_turn>\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"**Cell 6: Configure LoRA (Parameter-Efficient Fine-Tuning)**\n\nIn this cell, we prepare the Gemma 2B model for LoRA-based fine-tuning. LoRA (Low-Rank Adaptation) allows us to update only a small subset of parameters instead of the full model, making fine-tuning memory- and compute-efficient, especially for large models like Gemma 2B.\n\n* r = 16: The rank of the low-rank matrices injected into the model. Higher rank allows more capacity for adaptation but increases memory usage.\n\n* lora_alpha = 32: Scaling factor that balances the contribution of LoRA updates to the original weights.\n\n* target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]: Specifies which layers of the model will receive LoRA adapters. These include attention projection layers and MLP layers, which are critical for capturing task-specific behavior.\n\n* lora_dropout = 0.05: Applies a small dropout to LoRA updates for stability and regularization. Can be set to 0 if desired.\n\n* bias = \"none\": Keeps the original biases frozen and only trains LoRA parameters.\n\n* use_gradient_checkpointing = \"unsloth\": Enables memory-efficient backpropagation by storing fewer intermediate activations. This is crucial for training large models with limited GPU memory.\n\n* random_state = 3407: Ensures reproducibility of LoRA initialization.\n\n* use_rslora = False: Optional feature for rank-stabilized LoRA; only set True if using RSLora.\n\n* loftq_config = None: Reserved for LoFTQ quantization; not needed in our current setup.\n\nOverall, this configuration allows us to adapt Gemma 2B to our task efficiently, keeping memory consumption low while still enabling the model to learn the SOAP note summarization task effectively.\n\nOutput: Confirms that LoRA adapters are successfully applied to the model.","metadata":{}},{"cell_type":"code","source":"# Cell 6\n\n# Configure the model for LoRA (Parameter-Efficient Fine-Tuning)\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=16,\n    lora_alpha=32,\n    target_modules=[\n        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",   # Attention projections\n        \"gate_proj\", \"up_proj\", \"down_proj\"       # MLP projections\n    ],\n    lora_dropout=0.05,  # Small dropout for stability (can set to 0 if needed)\n    bias=\"none\",\n    use_gradient_checkpointing=\"unsloth\",  # Memory-efficient training\n    random_state=3407,\n    use_rslora=False,   # Set True only if using rank-stabilized LoRA (RSLora)\n    loftq_config=None,  # Not needed unless using LoFTQ quantization\n)\n\nprint(\"LoRA adapters successfully configured on the Gemma 2B model.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T03:15:26.035472Z","iopub.execute_input":"2025-10-26T03:15:26.036226Z","iopub.status.idle":"2025-10-26T03:15:32.901918Z","shell.execute_reply.started":"2025-10-26T03:15:26.036200Z","shell.execute_reply":"2025-10-26T03:15:32.900947Z"}},"outputs":[{"name":"stderr","text":"Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\nUnsloth will patch all other layers, except LoRA matrices, causing a performance hit.\nUnsloth 2025.10.9 patched 18 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ LoRA adapters successfully configured on the Gemma 2B model.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"**Cell 7: Define Training Arguments**\n\nWe define the hyperparameters for our fine-tuning process using the TrainingArguments class from the Hugging Face Transformers library. These settings are optimized for Gemma 2B fine-tuning with LoRA and 4-bit quantization using Unsloth. Each parameter is carefully chosen to balance training stability, speed, and memory efficiency.\n\n* output_dir = \"./outputs\": Directory where model checkpoints and logs will be saved.\n\n* num_train_epochs = 1: A single epoch is often sufficient for instruction fine-tuning, as the goal is to align the model with task-specific behavior rather than train from scratch.\n\n* per_device_train_batch_size = 2: Small batch size ensures that the 4-bit quantized model fits comfortably within GPU memory limits.\n\n* gradient_accumulation_steps = 4: Accumulates gradients over 4 mini-batches before performing an optimization step. This effectively simulates a larger batch size of 2 √ó 4 = 8, enhancing training stability without extra memory usage.\n\n* warmup_steps = 5: Gradually increases the learning rate during the initial steps to prevent training instability and allow smoother convergence.\n\n* learning_rate = 2e-4: A standard and reliable learning rate for QLoRA-based fine-tuning of instruction-tuned models.\n\n* fp16 = not torch.cuda.is_bf16_supported(): Enables half-precision (16-bit) floating-point computation on GPUs that don‚Äôt support bf16, improving speed and reducing memory use.\n\n* bf16 = torch.cuda.is_bf16_supported(): Enables bf16 precision when supported (e.g., A100, H100 GPUs) for faster and more stable mixed-precision training.\n\n* optim = \"adamw_8bit\": Uses a memory-efficient 8-bit version of the AdamW optimizer, significantly reducing GPU memory consumption.\n\n* weight_decay = 0.01: Adds a small regularization term to prevent overfitting during fine-tuning.\n\n* lr_scheduler_type = \"linear\": Uses a linear learning rate schedule, which gradually decays the learning rate as training progresses.\n\n* logging_steps = 10: Logs training progress every 10 steps for easier monitoring.\n\n* report_to = \"none\": Disables third-party logging integrations like Weights & Biases for a cleaner local training setup.\n\nOverall, these configurations are ideal for parameter-efficient fine-tuning (PEFT) on limited GPU resources while maintaining strong model performance and stable convergence.","metadata":{}},{"cell_type":"code","source":"# Cell 7\n\nfrom transformers import TrainingArguments\n\n# Define the training arguments for Gemma 2B LoRA fine-tuning\ntraining_args = TrainingArguments(\n    output_dir=\"./outputs\",              # Directory to save model checkpoints and logs\n    num_train_epochs=1,                  # Number of epochs (increase for full training)\n    per_device_train_batch_size=2,       # Small batch size for memory efficiency\n    gradient_accumulation_steps=4,       # Accumulate gradients to simulate larger batches\n    warmup_steps=5,                      # Steps for LR warm-up\n    learning_rate=2e-4,                  # Good default for LoRA + 4-bit\n    fp16=not torch.cuda.is_bf16_supported(),  # Use fp16 if bf16 not available\n    bf16=torch.cuda.is_bf16_supported(),      # Prefer bf16 on newer GPUs (A100, H100)\n    logging_steps=10,                    # Log every 10 steps\n    save_strategy=\"epoch\",               # Save checkpoints each epoch\n    save_total_limit=2,                  # Keep only last 2 checkpoints\n    optim=\"adamw_8bit\",                  # Memory-efficient optimizer from bitsandbytes\n    weight_decay=0.01,                   # Regularization\n    lr_scheduler_type=\"linear\",          # Linear LR schedule\n    seed=3407,                           # Reproducibility\n    report_to=\"none\",                    # Disable external logging (e.g., W&B)\n)\n\nprint(\"Training arguments configured successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T03:15:51.034737Z","iopub.execute_input":"2025-10-26T03:15:51.035018Z","iopub.status.idle":"2025-10-26T03:15:51.079884Z","shell.execute_reply.started":"2025-10-26T03:15:51.034994Z","shell.execute_reply":"2025-10-26T03:15:51.079074Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Training arguments configured successfully.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"**Cell 8: Initialize SFTTrainer and Start Fine-Tuning**\n\nIn this cell, we initialize the SFTTrainer from the trl library to perform LoRA-based fine-tuning of Gemma 2B on our SOAP summarization task. This trainer handles the complete training loop, including gradient accumulation, mixed-precision training, and evaluation on the validation dataset.\n\n* model = model: The Gemma 2B model with LoRA adapters applied in Cell 6, ready for parameter-efficient fine-tuning.\n\n* tokenizer = tokenizer: Ensures that all input prompts are tokenized using Gemma‚Äôs chat template for proper instruction-following behavior.\n\n* train_dataset / eval_dataset: The datasets preprocessed with format_chat_template in Cell 5, where each example is formatted as a clear instruction-response pair.\n\n* dataset_text_field = \"text\": Specifies the column in the dataset containing the formatted prompts and responses.\n\n* max_seq_length = max_seq_length: Ensures all sequences are truncated or padded to a consistent length for stable training.\n\n* dataset_num_proc = 2: Uses 2 parallel processes to speed up dataset preprocessing.\n\n* packing = False: Disables sequence packing; useful for dialogue-style sequences where prompts and responses should remain separate.\n\n* args = training_args: Passes the hyperparameters defined in Cell 7, which are optimized for memory-efficient, stable fine-tuning with LoRA.\n\n* trainer.train(): Starts the fine-tuning process, handling all forward and backward passes, gradient accumulation, optimizer steps, and mixed-precision computations automatically.\n\nThis setup ensures that Gemma 2B learns the instruction-following task efficiently, while keeping GPU memory usage low and maintaining training stability.","metadata":{}},{"cell_type":"code","source":"# Cell 8\n\nfrom trl import SFTTrainer\n\nprint(\"üöÄ Initializing the SFTTrainer...\")\n\n# Initialize the trainer for LoRA fine-tuning\ntrainer = SFTTrainer(\n    model=model,                             # Gemma 2B model with LoRA adapters\n    tokenizer=tokenizer,                     # Corresponding tokenizer\n    train_dataset=train_dataset_formatted,   # Preprocessed training dataset\n    eval_dataset=validation_dataset_formatted, # Preprocessed validation dataset\n    dataset_text_field=\"text\",               # Field containing the formatted prompt text\n    max_seq_length=max_seq_length,           # Maximum sequence length\n    dataset_num_proc=2,                      # Number of processes for dataset preprocessing\n    packing=False,                           # Disable packing for dialogue tasks; can enable for very short sequences\n    args=training_args,                      # Training arguments defined in Cell 7\n)\n\n# Start the fine-tuning process\nprint(\"Starting model training...\")\ntrainer_stats = trainer.train()\nprint(\"Training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T03:16:00.238712Z","iopub.execute_input":"2025-10-26T03:16:00.239423Z","iopub.status.idle":"2025-10-26T06:28:42.707662Z","shell.execute_reply.started":"2025-10-26T03:16:00.239387Z","shell.execute_reply":"2025-10-26T06:28:42.706942Z"}},"outputs":[{"name":"stdout","text":"üöÄ Initializing the SFTTrainer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/9250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d05759389189419f895c9ff7c5ad25e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"026f28e093a04bc8936cbb4337396317"}},"metadata":{}},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 9,250 | Num Epochs = 1 | Total steps = 579\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n \"-____-\"     Trainable parameters = 19,611,648 of 2,525,784,064 (0.78% trained)\n","output_type":"stream"},{"name":"stdout","text":"Starting model training...\nUnsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='579' max='579' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [579/579 3:11:46, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.246700</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.833300</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.758700</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.762200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.808100</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.810200</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.806400</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.768200</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.750100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.752900</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.733000</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.697700</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.672200</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.689800</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.673000</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.647800</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.678400</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.668800</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>1.631500</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.630200</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>1.688000</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>1.660500</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>1.647900</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.638100</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.651200</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>1.622900</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.662100</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>1.675000</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>1.689400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.663500</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>1.642900</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>1.640900</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>1.638400</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>1.657500</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.657300</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>1.674800</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>1.672700</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>1.662700</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>1.670600</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.681500</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>1.645000</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>1.677800</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>1.704800</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>1.679800</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.692700</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>1.704200</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>1.694500</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>1.712500</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>1.689600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.713100</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>1.688700</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>1.700600</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>1.689100</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>1.735000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.715600</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>1.700200</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>1.689200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Training complete.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"**Cell 9: Save Fine-Tuned LoRA Adapters and Tokenizer**\n\nAfter completing the LoRA fine-tuning, it is crucial to save the trained adapters and tokenizer for future use, such as inference, further fine-tuning, or deployment. This ensures that the model can be reloaded exactly as it was trained, maintaining the instruction-following behavior.\n\n* output_directory: Specifies the folder where the model adapters and tokenizer will be saved. Using a descriptive name helps identify the model and task.\n\n* os.makedirs(output_directory, exist_ok=True): Creates the directory if it doesn‚Äôt already exist, preventing errors during saving.\n\n* model.save_pretrained(output_directory): Saves the LoRA adapters (parameter-efficient fine-tuning weights) to the directory. If LoRA adapters are not applied, it saves the full model weights.\n\n* tokenizer.save_pretrained(output_directory): Saves the tokenizer configuration and vocabulary, ensuring consistent tokenization when the model is later loaded for inference.\n\n* print statements: Confirm that the adapters and tokenizer have been saved successfully, providing clear feedback for the user.\n\nThis step finalizes the training workflow, producing a ready-to-use fine-tuned Gemma 2B model that can generate SOAP notes from medical dialogues.","metadata":{}},{"cell_type":"code","source":"# Cell 9\n\nimport os\n\n# Define the output directory\noutput_directory = \"lora-fine-tuned-gemma-2b-medical-dialogue-to-soap-summary\"\n\n# Create the directory if it doesn't exist\nos.makedirs(output_directory, exist_ok=True)\n\n# Save only the LoRA adapters (parameter-efficient fine-tuning)\nif hasattr(model, \"peft_config\"):\n    print(\"Saving LoRA adapters...\")\n    model.save_pretrained(output_directory)\nelse:\n    print(\"No LoRA adapters found. Saving full model instead.\")\n    model.save_pretrained(output_directory)\n\n# Save the tokenizer\nprint(\"Saving tokenizer...\")\ntokenizer.save_pretrained(output_directory)\n\nprint(f\"Model adapters and tokenizer successfully saved to '{output_directory}'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T06:29:06.049440Z","iopub.execute_input":"2025-10-26T06:29:06.049742Z","iopub.status.idle":"2025-10-26T06:29:06.940734Z","shell.execute_reply.started":"2025-10-26T06:29:06.049720Z","shell.execute_reply":"2025-10-26T06:29:06.939696Z"}},"outputs":[{"name":"stdout","text":"Saving LoRA adapters...\nSaving tokenizer...\nModel adapters and tokenizer successfully saved to 'lora-fine-tuned-gemma-2b-medical-dialogue-to-soap-summary'.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# zip the finetuned model\n\nimport shutil\n\n# Define the path to the model directory and the zip output path\nmodel_dir = '/kaggle/working/lora-fine-tuned-gemma-2b-medical-dialogue-to-soap-summary'\nzip_output = '/kaggle/working/lora_fine_tuned_model.zip'\n\n# Create a zip archive of the model directory\nshutil.make_archive(zip_output.replace('.zip', ''), 'zip', model_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T06:29:45.398828Z","iopub.execute_input":"2025-10-26T06:29:45.399610Z","iopub.status.idle":"2025-10-26T06:29:50.572676Z","shell.execute_reply.started":"2025-10-26T06:29:45.399581Z","shell.execute_reply":"2025-10-26T06:29:50.571765Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/lora_fine_tuned_model.zip'"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"**Cell 10: Evaluate Baseline Gemma 2B Model**\n\nIn this cell, we evaluate the original, unfine-tuned Gemma 2B model on a sample from the test dataset. This provides a baseline performance to compare against the fine-tuned LoRA model, helping us understand how much improvement the instruction fine-tuning has achieved.\n\n* base_model, base_tokenizer: Loads the original Gemma 2B model and tokenizer in 4-bit precision for memory-efficient evaluation.\n\n* base_model.to(\"cuda\") & base_model.eval(): Moves the model to GPU and sets it to evaluation mode, disabling dropout and other training behaviors.\n\n* num_samples = 1: Specifies how many test samples to generate summaries for. Can be increased for more comprehensive evaluation.\n\n* messages: Formats the user input as a clear instruction prompt (‚ÄúSummarize the following medical dialogue into a SOAP note‚Äù) to align with the model‚Äôs instruction-following capability.\n\n* prompt = base_tokenizer.apply_chat_template(...): Converts the messages into the proper chat template expected by Gemma 2B, ensuring the model receives input in the same structured format as during training.\n\n* inputs & attention_mask: Tokenizes the prompt and generates an attention mask to tell the model which tokens to pay attention to.\n\n* base_model.generate(...): Produces the summary for the given dialogue using the baseline model.\n\n* baseline_summary = base_tokenizer.batch_decode(...): Decodes the generated token IDs into readable text, skipping special tokens.\n\n* Print statements: Display the original dialogue, reference SOAP summary, and the generated summary from the baseline model for easy side-by-side comparison.\n\nThis evaluation step is essential to measure the improvement after fine-tuning, giving a clear quantitative and qualitative comparison between the pretrained baseline and the LoRA-adapted model.","metadata":{}},{"cell_type":"code","source":"# Cell 10\n\nimport torch\nfrom unsloth import FastLanguageModel\n\n# Load the original base Gemma 2B model and tokenizer for baseline comparison\nprint(\"Loading the original base Gemma 2B model...\")\nbase_model, base_tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/gemma-2b-it-bnb-4bit\",\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n    trust_remote_code=True,  # Ensure custom model code is loaded\n)\n\n# DO NOT use `.to(\"cuda\")` for 4-bit or 8-bit models\nbase_model.eval()  # Set to evaluation mode\n\n# Number of test samples to evaluate\nnum_samples = 1  # Adjust as needed\n\nfor i in range(num_samples):\n    # Select a sample from the test dataset\n    sample = test_dataset[i]\n    dialogue = sample[\"dialogue\"]\n    reference_summary = sample[\"soap\"]\n\n    # Format the messages using the chat template\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": f\"Summarize the following medical dialogue into a SOAP note:\\n\\n{dialogue}\"\n        }\n    ]\n\n    # Format prompt using the tokenizer's chat template\n    prompt = base_tokenizer.apply_chat_template(\n        messages, \n        tokenize=False, \n        add_generation_prompt=True\n    )\n\n    # Tokenize the prompt and move inputs to GPU\n    inputs = base_tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n\n    # Create attention mask\n    attention_mask = (inputs[\"input_ids\"] != base_tokenizer.pad_token_id).to(torch.long)\n\n    # Generate output from the baseline (unfine-tuned) model\n    print(f\"\\nGenerating summary for sample {i + 1} (BASE model)...\")\n    outputs = base_model.generate(\n        input_ids=inputs[\"input_ids\"],\n        attention_mask=attention_mask,\n        max_new_tokens=512,\n        eos_token_id=base_tokenizer.eos_token_id,\n        pad_token_id=base_tokenizer.pad_token_id\n    )\n\n    # Decode the generated summary\n    baseline_summary = base_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    generated_summary = baseline_summary[0]\n\n    # Print results for comparison\n    print(\"\\n--- BASELINE MODEL (NO FINE-TUNING) ---\")\n    print(\"\\nDIALOGUE:\")\n    print(dialogue)\n    print(\"\\nREFERENCE SOAP SUMMARY:\")\n    print(reference_summary)\n    print(\"\\nGENERATED SUMMARY (BASELINE):\")\n    print(generated_summary)\n    print(\"\\n--- END OF BASELINE ---\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T06:33:23.207380Z","iopub.execute_input":"2025-10-26T06:33:23.208054Z","iopub.status.idle":"2025-10-26T06:33:49.408835Z","shell.execute_reply.started":"2025-10-26T06:33:23.208011Z","shell.execute_reply":"2025-10-26T06:33:49.408088Z"}},"outputs":[{"name":"stdout","text":"Loading the original base Gemma 2B model...\nUnsloth: WARNING `trust_remote_code` is True.\nAre you certain you want to do remote code execution?\n==((====))==  Unsloth 2025.10.9: Fast Gemma patching. Transformers: 4.56.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n\nGenerating summary for sample 1 (BASE model)...\n\n--- BASELINE MODEL (NO FINE-TUNING) ---\n\nDIALOGUE:\nDoctor: Hello, can you please tell me about your past medical history?\nPatient: Hi, I don't have any past medical history.\nDoctor: Okay. What brings you in today?\nPatient: I've been experiencing painless blurry vision in my right eye for a week now. I've also had intermittent fevers, headache, body aches, and a nonpruritic maculopapular rash on my lower legs for the past 6 months.\nDoctor: Thank you for sharing that. Have you had any other symptoms such as neck stiffness, nausea, vomiting, Raynaud's phenomenon, oral ulcerations, chest pain, shortness of breath, abdominal pain, or photosensitivity?\nPatient: No, only an isolated episode of left knee swelling and testicular swelling in the past.\nDoctor: Do you work with any toxic substances or have any habits like smoking, drinking, or illicit drug use?\nPatient: No, I work as a flooring installer and I don't have any toxic habits.\nDoctor: Alright. We checked your vital signs and they were normal. During the physical exam, we found bilateral papilledema and optic nerve erythema in your right eye, which was greater than in your left eye. You also have a right inferior nasal quadrant visual field defect and a right afferent pupillary defect. Your muscle strength and reflexes were normal, and your sensation to light touch, pinprick, vibration, and proprioception was intact. We also noticed the maculopapular rash on your bilateral lower extremities.\nPatient: Oh, I see.\nDoctor: Your admitting labs showed some abnormal results. You have microcytic anemia with a hemoglobin of 11.6 gm/dL, hematocrit of 35.3%, and mean corpuscular volume of 76.9 fL. You also have hyponatremia with a sodium level of 133 mmol/L. Your erythrocyte sedimentation rate (ESR) is elevated at 33 mm/hr, and your C-reactive protein (CRP) is also elevated at 13.3 mg/L. Your urinalysis did not show any protein or blood.\nPatient: Okay. What does that mean?\nDoctor: These results could indicate an underlying inflammatory or infectious process. We also performed a lumbar puncture, which showed clear and colorless fluid, 2 red blood cells per microliter, and 56 white blood cells per microliter.\nPatient: So, what's the next step?\nDoctor: We need to investigate further to determine the cause of your symptoms. We'll run additional tests and consult with a specialist to get a clearer understanding of your condition. In the meantime, we'll monitor your symptoms and provide supportive care. We'll keep you informed about any new findings and discuss the best course of treatment.\nPatient: Alright, thank you, Doctor.\n\nREFERENCE SOAP SUMMARY:\nS: The patient, a flooring installer with no significant past medical history, presents with painless blurry vision in the right eye for one week, intermittent fevers, headaches, body aches, and a nonpruritic maculopapular rash on the lower legs for six months. The patient also reports an isolated episode of left knee and testicular swelling in the past but denies any neck stiffness, nausea, vomiting, Raynaud's phenomenon, oral ulcerations, chest pain, shortness of breath, abdominal pain, or photosensitivity. No history of exposure to toxic substances or habits related to smoking, drinking, or illicit drug use.\nO: Vital signs are normal. Physical examination reveals bilateral papilledema, greater optic nerve erythema in the right eye, a right inferior nasal quadrant visual field defect, and a right afferent pupillary defect. Muscle strength, reflexes, and sensation to light touch, pinprick, vibration, and proprioception are intact. A maculopapular rash is noted on bilateral lower extremities. Lab findings include microcytic anemia (Hemoglobin: 11.6 gm/dL, Hematocrit: 35.3%, MCV: 76.9 fL), hyponatremia (Sodium: 133 mmol/L), elevated ESR (33 mm/hr), and CRP (13.3 mg/L). Urinalysis is normal. Lumbar puncture shows clear fluid, 2 RBCs/¬µL, and 56 WBCs/¬µL.\nA: The patient's symptoms and findings suggest a possible inflammatory or infectious process affecting multiple systems, including the central nervous system, as indicated by papilledema and abnormal lumbar puncture results. Differential diagnoses could include autoimmune conditions, infectious diseases, or other systemic inflammatory disorders. The presence of optic nerve involvement and systemic symptoms necessitates further investigation to narrow down the causes.\nP: Plan to conduct additional diagnostic tests to explore underlying causes, including imaging studies and specific serological tests. Consultation with a neurologist and possibly a rheumatologist or infectious disease specialist is recommended. Monitor the patient's symptoms closely and provide supportive care as needed. Educate the patient about the findings and the importance of follow-up for further evaluation and management. Ensure the patient understands the potential seriousness of the symptoms and the need for thorough investigation and possibly long-term management.\n\nGENERATED SUMMARY (BASELINE):\nuser\nSummarize the following medical dialogue into a SOAP note:\n\nDoctor: Hello, can you please tell me about your past medical history?\nPatient: Hi, I don't have any past medical history.\nDoctor: Okay. What brings you in today?\nPatient: I've been experiencing painless blurry vision in my right eye for a week now. I've also had intermittent fevers, headache, body aches, and a nonpruritic maculopapular rash on my lower legs for the past 6 months.\nDoctor: Thank you for sharing that. Have you had any other symptoms such as neck stiffness, nausea, vomiting, Raynaud's phenomenon, oral ulcerations, chest pain, shortness of breath, abdominal pain, or photosensitivity?\nPatient: No, only an isolated episode of left knee swelling and testicular swelling in the past.\nDoctor: Do you work with any toxic substances or have any habits like smoking, drinking, or illicit drug use?\nPatient: No, I work as a flooring installer and I don't have any toxic habits.\nDoctor: Alright. We checked your vital signs and they were normal. During the physical exam, we found bilateral papilledema and optic nerve erythema in your right eye, which was greater than in your left eye. You also have a right inferior nasal quadrant visual field defect and a right afferent pupillary defect. Your muscle strength and reflexes were normal, and your sensation to light touch, pinprick, vibration, and proprioception was intact. We also noticed the maculopapular rash on your bilateral lower extremities.\nPatient: Oh, I see.\nDoctor: Your admitting labs showed some abnormal results. You have microcytic anemia with a hemoglobin of 11.6 gm/dL, hematocrit of 35.3%, and mean corpuscular volume of 76.9 fL. You also have hyponatremia with a sodium level of 133 mmol/L. Your erythrocyte sedimentation rate (ESR) is elevated at 33 mm/hr, and your C-reactive protein (CRP) is also elevated at 13.3 mg/L. Your urinalysis did not show any protein or blood.\nPatient: Okay. What does that mean?\nDoctor: These results could indicate an underlying inflammatory or infectious process. We also performed a lumbar puncture, which showed clear and colorless fluid, 2 red blood cells per microliter, and 56 white blood cells per microliter.\nPatient: So, what's the next step?\nDoctor: We need to investigate further to determine the cause of your symptoms. We'll run additional tests and consult with a specialist to get a clearer understanding of your condition. In the meantime, we'll monitor your symptoms and provide supportive care. We'll keep you informed about any new findings and discuss the best course of treatment.\nPatient: Alright, thank you, Doctor.\nmodel\n**SOAP Note**\n\n**Patient:**\n- No past medical history.\n- Presenting with bilateral papilledema and optic nerve erythema in the right eye, along with right inferior nasal quadrant visual field defect and right afferent pupillary defect.\n- Microcytic anemia with a hemoglobin of 11.6 gm/dL, hematocrit of \n\n--- END OF BASELINE ---\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"**Cell 11: Evaluate Fine-Tuned Gemma 2B Model**\n\nIn this cell, we evaluate the fine-tuned Gemma 2B model on a sample from the test dataset. This allows us to see how well the model generates SOAP notes after LoRA-based instruction fine-tuning, and to compare it with the baseline model.\n\n* fine_tuned_model, fine_tuned_tokenizer: Loads the Gemma 2B model fine-tuned on medical dialogues and the corresponding tokenizer. Using load_in_4bit ensures memory-efficient loading.\n\n* fine_tuned_model.to(\"cuda\") & fine_tuned_model.eval(): Moves the model to GPU and sets evaluation mode to disable dropout, ensuring deterministic outputs.\n\n* num_samples = 1: Specifies how many test samples to evaluate; can be increased for more extensive testing.\n\n* messages: Formats the user input as a clear instruction prompt, telling the model to summarize the dialogue into a SOAP note.\n\n* prompt = fine_tuned_tokenizer.apply_chat_template(...): Converts the messages into the proper chat template expected by Gemma 2B, maintaining consistency with training.\n\n* inputs & attention_mask: Tokenizes the prompt and creates an attention mask, indicating which tokens the model should attend to.\n\n* torch.no_grad(): Disables gradient computation to save memory and speed up inference since we are only generating outputs.\n\n* fine_tuned_model.generate(...): Generates the SOAP note for the given dialogue, using max_new_tokens to control the output length and properly handling EOS and padding tokens.\n\n* fine_tuned_tokenizer.batch_decode(...): Decodes the generated tokens into readable text. The assistant‚Äôs response is extracted with .split(\"assistant\\n\")[-1].strip() to ensure only the generated SOAP note is evaluated.\n\n* Print statements: Display the original dialogue, reference SOAP summary, and the generated summary from the fine-tuned model, making it easy to compare qualitative improvements over the baseline.\n\nThis step demonstrates the effectiveness of LoRA fine-tuning and provides concrete examples of how the model performs on real medical dialogues, forming the basis for both qualitative and quantitative evaluation.","metadata":{}},{"cell_type":"code","source":"# Cell 11\n\nimport torch\nfrom unsloth import FastLanguageModel\nimport re  # For cleaning output\n\n# Load the fine-tuned Gemma 2B model and tokenizer\nprint(\"Loading the fine-tuned model for evaluation...\")\nfine_tuned_model, fine_tuned_tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"aslamsikder/lora-fine-tuned-gemma-2b-medical-dialogue-to-soap-summary\",\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n    trust_remote_code=True,\n)\n\nfine_tuned_model.eval()  # Set to evaluation mode\n\nnum_samples = 1  # Adjust as needed\n\nfor i in range(num_samples):\n    sample = test_dataset[i]\n    dialogue = sample[\"dialogue\"]\n    reference_summary = sample[\"soap\"]\n\n    # Prepare chat messages\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": f\"Summarize the following medical dialogue into a SOAP note perfectly:\\n\\n{dialogue}\"\n        }\n    ]\n\n    prompt = fine_tuned_tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n\n    inputs = fine_tuned_tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n    attention_mask = (inputs[\"input_ids\"] != fine_tuned_tokenizer.pad_token_id).to(torch.long)\n\n    print(f\"\\nGenerating summary for sample {i + 1} (FINE-TUNED model)...\")\n    with torch.no_grad():\n        outputs = fine_tuned_model.generate(\n            input_ids=inputs[\"input_ids\"],\n            attention_mask=attention_mask,\n            max_new_tokens=512,\n            eos_token_id=fine_tuned_tokenizer.eos_token_id,\n            pad_token_id=fine_tuned_tokenizer.pad_token_id\n        )\n\n    # Decode and clean output\n    fine_tuned_summary = fine_tuned_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    raw_output = fine_tuned_summary[0]\n\n    # Remove assistant/user prefixes and unwanted artifacts\n    cleaned_output = re.sub(r'^(user|model|assistant)\\n', '', raw_output, flags=re.IGNORECASE)\n    cleaned_output = re.sub(r'strtoA:.*', '', cleaned_output)  # Remove strtoA lines\n    cleaned_output = cleaned_output.strip()\n\n    print(\"\\n--- FINE-TUNED MODEL (CLEANED) ---\")\n    print(\"\\nDIALOGUE:\")\n    print(dialogue)\n    print(\"\\nREFERENCE SOAP SUMMARY:\")\n    print(reference_summary)\n    print(\"\\nGENERATED SUMMARY (FINE-TUNED):\")\n    print(cleaned_output)\n    print(\"\\n--- END OF FINE-TUNED ---\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T06:48:22.690193Z","iopub.execute_input":"2025-10-26T06:48:22.690596Z","iopub.status.idle":"2025-10-26T06:48:56.689711Z","shell.execute_reply.started":"2025-10-26T06:48:22.690574Z","shell.execute_reply":"2025-10-26T06:48:56.688838Z"}},"outputs":[{"name":"stdout","text":"Loading the fine-tuned model for evaluation...\nUnsloth: WARNING `trust_remote_code` is True.\nAre you certain you want to do remote code execution?\n==((====))==  Unsloth 2025.10.9: Fast Gemma patching. Transformers: 4.56.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n\nGenerating summary for sample 1 (FINE-TUNED model)...\n\n--- FINE-TUNED MODEL (CLEANED) ---\n\nDIALOGUE:\nDoctor: Hello, can you please tell me about your past medical history?\nPatient: Hi, I don't have any past medical history.\nDoctor: Okay. What brings you in today?\nPatient: I've been experiencing painless blurry vision in my right eye for a week now. I've also had intermittent fevers, headache, body aches, and a nonpruritic maculopapular rash on my lower legs for the past 6 months.\nDoctor: Thank you for sharing that. Have you had any other symptoms such as neck stiffness, nausea, vomiting, Raynaud's phenomenon, oral ulcerations, chest pain, shortness of breath, abdominal pain, or photosensitivity?\nPatient: No, only an isolated episode of left knee swelling and testicular swelling in the past.\nDoctor: Do you work with any toxic substances or have any habits like smoking, drinking, or illicit drug use?\nPatient: No, I work as a flooring installer and I don't have any toxic habits.\nDoctor: Alright. We checked your vital signs and they were normal. During the physical exam, we found bilateral papilledema and optic nerve erythema in your right eye, which was greater than in your left eye. You also have a right inferior nasal quadrant visual field defect and a right afferent pupillary defect. Your muscle strength and reflexes were normal, and your sensation to light touch, pinprick, vibration, and proprioception was intact. We also noticed the maculopapular rash on your bilateral lower extremities.\nPatient: Oh, I see.\nDoctor: Your admitting labs showed some abnormal results. You have microcytic anemia with a hemoglobin of 11.6 gm/dL, hematocrit of 35.3%, and mean corpuscular volume of 76.9 fL. You also have hyponatremia with a sodium level of 133 mmol/L. Your erythrocyte sedimentation rate (ESR) is elevated at 33 mm/hr, and your C-reactive protein (CRP) is also elevated at 13.3 mg/L. Your urinalysis did not show any protein or blood.\nPatient: Okay. What does that mean?\nDoctor: These results could indicate an underlying inflammatory or infectious process. We also performed a lumbar puncture, which showed clear and colorless fluid, 2 red blood cells per microliter, and 56 white blood cells per microliter.\nPatient: So, what's the next step?\nDoctor: We need to investigate further to determine the cause of your symptoms. We'll run additional tests and consult with a specialist to get a clearer understanding of your condition. In the meantime, we'll monitor your symptoms and provide supportive care. We'll keep you informed about any new findings and discuss the best course of treatment.\nPatient: Alright, thank you, Doctor.\n\nREFERENCE SOAP SUMMARY:\nS: The patient, a flooring installer with no significant past medical history, presents with painless blurry vision in the right eye for one week, intermittent fevers, headaches, body aches, and a nonpruritic maculopapular rash on the lower legs for six months. The patient also reports an isolated episode of left knee and testicular swelling in the past but denies any neck stiffness, nausea, vomiting, Raynaud's phenomenon, oral ulcerations, chest pain, shortness of breath, abdominal pain, or photosensitivity. No history of exposure to toxic substances or habits related to smoking, drinking, or illicit drug use.\nO: Vital signs are normal. Physical examination reveals bilateral papilledema, greater optic nerve erythema in the right eye, a right inferior nasal quadrant visual field defect, and a right afferent pupillary defect. Muscle strength, reflexes, and sensation to light touch, pinprick, vibration, and proprioception are intact. A maculopapular rash is noted on bilateral lower extremities. Lab findings include microcytic anemia (Hemoglobin: 11.6 gm/dL, Hematocrit: 35.3%, MCV: 76.9 fL), hyponatremia (Sodium: 133 mmol/L), elevated ESR (33 mm/hr), and CRP (13.3 mg/L). Urinalysis is normal. Lumbar puncture shows clear fluid, 2 RBCs/¬µL, and 56 WBCs/¬µL.\nA: The patient's symptoms and findings suggest a possible inflammatory or infectious process affecting multiple systems, including the central nervous system, as indicated by papilledema and abnormal lumbar puncture results. Differential diagnoses could include autoimmune conditions, infectious diseases, or other systemic inflammatory disorders. The presence of optic nerve involvement and systemic symptoms necessitates further investigation to narrow down the causes.\nP: Plan to conduct additional diagnostic tests to explore underlying causes, including imaging studies and specific serological tests. Consultation with a neurologist and possibly a rheumatologist or infectious disease specialist is recommended. Monitor the patient's symptoms closely and provide supportive care as needed. Educate the patient about the findings and the importance of follow-up for further evaluation and management. Ensure the patient understands the potential seriousness of the symptoms and the need for thorough investigation and possibly long-term management.\n\nGENERATED SUMMARY (FINE-TUNED):\nSummarize the following medical dialogue into a SOAP note perfectly:\n\nDoctor: Hello, can you please tell me about your past medical history?\nPatient: Hi, I don't have any past medical history.\nDoctor: Okay. What brings you in today?\nPatient: I've been experiencing painless blurry vision in my right eye for a week now. I've also had intermittent fevers, headache, body aches, and a nonpruritic maculopapular rash on my lower legs for the past 6 months.\nDoctor: Thank you for sharing that. Have you had any other symptoms such as neck stiffness, nausea, vomiting, Raynaud's phenomenon, oral ulcerations, chest pain, shortness of breath, abdominal pain, or photosensitivity?\nPatient: No, only an isolated episode of left knee swelling and testicular swelling in the past.\nDoctor: Do you work with any toxic substances or have any habits like smoking, drinking, or illicit drug use?\nPatient: No, I work as a flooring installer and I don't have any toxic habits.\nDoctor: Alright. We checked your vital signs and they were normal. During the physical exam, we found bilateral papilledema and optic nerve erythema in your right eye, which was greater than in your left eye. You also have a right inferior nasal quadrant visual field defect and a right afferent pupillary defect. Your muscle strength and reflexes were normal, and your sensation to light touch, pinprick, vibration, and proprioception was intact. We also noticed the maculopapular rash on your bilateral lower extremities.\nPatient: Oh, I see.\nDoctor: Your admitting labs showed some abnormal results. You have microcytic anemia with a hemoglobin of 11.6 gm/dL, hematocrit of 35.3%, and mean corpuscular volume of 76.9 fL. You also have hyponatremia with a sodium level of 133 mmol/L. Your erythrocyte sedimentation rate (ESR) is elevated at 33 mm/hr, and your C-reactive protein (CRP) is also elevated at 13.3 mg/L. Your urinalysis did not show any protein or blood.\nPatient: Okay. What does that mean?\nDoctor: These results could indicate an underlying inflammatory or infectious process. We also performed a lumbar puncture, which showed clear and colorless fluid, 2 red blood cells per microliter, and 56 white blood cells per microliter.\nPatient: So, what's the next step?\nDoctor: We need to investigate further to determine the cause of your symptoms. We'll run additional tests and consult with a specialist to get a clearer understanding of your condition. In the meantime, we'll monitor your symptoms and provide supportive care. We'll keep you informed about any new findings and discuss the best course of treatment.\nPatient: Alright, thank you, Doctor.\nmodel\nS: The patient, a flooring installer, reports experiencing painless blurry vision in the right eye for the past week. The patient also reports intermittent fevers, headache, body aches, and a nonpruritic maculopapular rash on the lower legs for the past 6 months. The patient denies any history of toxic habits, smoking, drinking, or illicit drug use.\nO: Vital signs were normal. Physical examination revealed bilateral papilledema and optic nerve erythema in the right eye, greater in the left, with bilateral inferior nasal quadrant visual field defect and right afferent pupillary defect. Muscle strength and reflexes were normal, and sensation to light touch, pinprick, vibration, and proprioception was intact. The maculopapular rash was noted on both bilateral lower extremities. Laboratory findings showed microcytic anemia with hemoglobin of 11.6 gm/dL, hematocrit of 35.3%, mean corpuscular volume of 76.9 fL, hyponatremia with a sodium level of 133 mmol/L, elevated erythrocyte sedimentation rate at 33 mm/hr, and CRP at 13.3 mg/L. Urinalysis showed no protein or blood. Lumbar puncture showed clear and colorless fluid, 2 red blood cells per microliter, and 56 white blood cells per microliter.\nA: The patient presents with symptoms suggestive of an inflammatory or infectious process, evidenced by the presence of papilledema, optic nerve erythema, visual field defects, and elevated lab values. Differential diagnoses could include an infectious or inflammatory process, such as a viral or bacterial infection, or an autoimmune condition.\nP: The management plan includes monitoring the patient's symptoms and supporting care. Further diagnostic tests such as additional imaging and possible blood tests will be performed to clarify theunderlying cause. The patient will be educated on the importance of reporting any new symptoms or changes in symptoms. Referral to a specialist for further evaluation and management is planned. Regular follow-up appointments will be scheduled to monitor the patient's progress and adjust treatment as necessary.\n\n--- END OF FINE-TUNED ---\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!pip install rouge_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T06:49:22.651498Z","iopub.execute_input":"2025-10-26T06:49:22.652192Z","iopub.status.idle":"2025-10-26T06:49:28.278239Z","shell.execute_reply.started":"2025-10-26T06:49:22.652165Z","shell.execute_reply":"2025-10-26T06:49:28.277439Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.3.0)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2025.9.18)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=d2fb0ead555b8a58d5fe7a2901163e0eb0c5e357e1e0b5eb58d6f65521fee288\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**Cell 12: Quantitative Evaluation on the Test Set**\n\nIn this cell, we evaluate the performance of the fine-tuned Gemma 2B model on the test dataset using standard text summarization metrics: ROUGE and BERTScore. This provides an objective measure of how well the model generates SOAP notes from medical dialogues.\n\n* predictions / references: Lists to store the generated summaries and their corresponding ground-truth SOAP notes.\n\n* messages: Formats the user input as a clear instruction (‚ÄúSummarize the following medical dialogue into a SOAP note‚Äù) using the chat template, ensuring consistency with training.\n\n* tokenizer.apply_chat_template(...): Converts the messages into the proper prompt format expected by Gemma 2B.\n\n* inputs & attention_mask: Tokenizes the prompt and generates the attention mask, telling the model which tokens to attend to during generation.\n\n* torch.no_grad(): Disables gradient calculation to save memory and speed up evaluation since no backpropagation is required.\n\n* model.generate(...): Generates the summary for each dialogue. max_new_tokens limits the summary length, while eos_token_id and pad_token_id ensure proper sequence termination and padding handling.\n\n* tokenizer.batch_decode(...): Decodes token IDs into readable text, skipping special tokens. The assistant‚Äôs response is extracted using .split(\"assistant\\n\")[-1].strip().\n\n* ROUGE: Evaluates overlap between generated summaries and reference SOAP notes, capturing precision, recall, and F1 for n-grams.\n\n* BERTScore: Measures semantic similarity between predictions and references using contextual embeddings; the average F1 score provides a single overall metric.\n\n* Print results: Displays ROUGE and BERTScore in a readable percentage format for easy comparison.\n\nThis evaluation step provides a quantitative benchmark to assess how much the fine-tuning improved the model over the baseline and helps validate the quality of generated SOAP notes.","metadata":{}},{"cell_type":"code","source":"# Cell 12\n\nimport torch\nfrom tqdm import tqdm\nimport evaluate\n\n# Load evaluation metrics\nrouge = evaluate.load('rouge')\nbertscore = evaluate.load(\"bertscore\")\n\n# Initialize lists to store predictions and references\npredictions = []\nreferences = []\n\nprint(\"\\nRunning quantitative evaluation on the test set...\")\n\n# Loop through the entire test dataset\nfor sample in tqdm(test_dataset):\n    dialogue = sample[\"dialogue\"]\n    reference = sample[\"soap\"]\n\n    # Format prompt for model using chat template\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": f\"Summarize the following medical dialogue into a SOAP note:\\n\\n{dialogue}\"\n        }\n    ]\n\n    prompt = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True  # Ensures the model generates an assistant response\n    )\n\n    # Tokenize and move to GPU\n    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n\n    # Generate summary from the fine-tuned model\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=inputs[\"input_ids\"],\n            attention_mask=(inputs[\"input_ids\"] != tokenizer.pad_token_id).to(torch.long),\n            max_new_tokens=512,\n            eos_token_id=tokenizer.eos_token_id,\n            pad_token_id=tokenizer.pad_token_id\n        )\n\n    # Decode generated text\n    generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    # Extract the assistant response\n    prediction = generated_text[0].split(\"assistant\\n\")[-1].strip()\n\n    # Append to lists\n    predictions.append(prediction)\n    references.append(reference)\n\n# Compute evaluation metrics\nrouge_results = rouge.compute(predictions=predictions, references=references)\nbertscore_results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n\n# Print results\nprint(\"\\n--- QUANTITATIVE EVALUATION RESULTS ---\")\nprint(\"\\nROUGE Scores:\")\nfor key, value in rouge_results.items():\n    print(f\"{key}: {value*100:.2f}\")\n\nprint(\"\\nBERTScore:\")\n# Use mean F1 score for summary evaluation\navg_bert_f1 = sum(bertscore_results['f1']) / len(bertscore_results['f1'])\nprint(f\"Average F1 Score: {avg_bert_f1*100:.2f}\")\nprint(\"\\n--- END OF EVALUATION ---\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T06:49:48.933131Z","iopub.execute_input":"2025-10-26T06:49:48.933819Z","iopub.status.idle":"2025-10-26T08:23:33.396207Z","shell.execute_reply.started":"2025-10-26T06:49:48.933793Z","shell.execute_reply":"2025-10-26T08:23:33.395372Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fd97df1cd194857a4e57fa6ff68b435"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"288fe98f7bba490aa7efc14844b4af56"}},"metadata":{}},{"name":"stdout","text":"\nRunning quantitative evaluation on the test set...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [1:32:32<00:00, 22.21s/it]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf8a5ec5657448a483ef7ab0d3a1cdf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0acc8e0440f4a3d919d09d0ee3bff71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e13d07e48d4fb385d2aecd64c0dbae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3849b0d3653b4e5e832799bdbd87db64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"147444316c9f4533bb16a97c43c60930"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eae3be9f9d640cc8134b1bdba561717"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n--- QUANTITATIVE EVALUATION RESULTS ---\n\nROUGE Scores:\nrouge1: 39.07\nrouge2: 23.26\nrougeL: 25.81\nrougeLsum: 35.72\n\nBERTScore:\nAverage F1 Score: 86.71\n\n--- END OF EVALUATION ---\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"**Cell 13: Deploy Fine-Tuned Gemma 2B Model via Flask API**\n\nThis cell sets up a Flask web API to allow remote inference with your fine-tuned Gemma 2B model. It provides a simple endpoint to submit medical dialogues and receive generated SOAP summaries, making the model accessible for web applications or integration with other tools.\n\n* Flask app initialization: app = Flask(__name__) creates the Flask application instance.\n\n* Model loading (outside request handler):\n\n- Loads the fine-tuned Gemma 2B model and tokenizer once to avoid repeated loading on each request.\n\n- load_in_4bit=True ensures memory-efficient loading.\n\n- model.to(\"cuda\") moves the model to GPU for faster inference.\n\n- model.eval() disables dropout and other training-specific layers for deterministic outputs.\n\n- FastLanguageModel.for_inference(model) optimizes the model for inference.\n\n* /summarize endpoint (POST):\n\n- Accepts JSON input containing a \"dialogue\" field.\n\n- Returns JSON output with the generated SOAP summary.\n\n* Prompt formatting:\n\n- The user input is converted into the Llama 3 chat template (messages ‚Üí prompt) to match the fine-tuning format.\n\n- add_generation_prompt=True ensures the model knows it should generate an assistant response.\n\n* Tokenization and attention mask:\n\n- The prompt is tokenized and moved to GPU.\n\n- The attention mask identifies which tokens are real versus padding, ensuring proper handling during generation.\n\n* Text generation:\n\n- torch.no_grad() disables gradient computation for memory efficiency.\n\n- model.generate(...) produces the summary with controlled length (max_new_tokens) and correct EOS/pad token handling.\n\n* Extract assistant response: generated_text[0].split(\"assistant\\n\")[-1].strip() ensures only the generated SOAP note is returned.\n\n* Error handling: Returns descriptive JSON errors if the model isn‚Äôt loaded, the input is invalid, or generation fails.\n\n* Running the app: app.run(host='0.0.0.0', port=7860) starts the server accessible on all network interfaces; 7860 is compatible with Hugging Face Spaces.\n\nThis setup provides a production-ready, lightweight API for generating SOAP notes from medical dialogues using the fine-tuned Gemma 2B model, making it easy to integrate into web apps or other services.","metadata":{}},{"cell_type":"code","source":"# Cell 13\n\nfrom flask import Flask, request, jsonify\nimport torch\nfrom unsloth import FastLanguageModel\n\n# Initialize Flask app\napp = Flask(__name__)\n\n# --- Model Loading (Load once, outside request handler) ---\ntry:\n    max_seq_length = 2048\n    dtype = None\n    load_in_4bit = True\n\n    # Load the fine-tuned Gemma 2B model and tokenizer\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=\"aslamsikder/fine-tuned-gemma-2b-medical-dialogue-to-soap-summary\",\n        max_seq_length=max_seq_length,\n        dtype=dtype,\n        load_in_4bit=load_in_4bit,\n        trust_remote_code=True  # Ensures custom Hugging Face code is loaded\n    )\n    model.to(\"cuda\")\n    model.eval()  # Set to evaluation mode\n    FastLanguageModel.for_inference(model)\n    print(\"Model loaded successfully for inference.\")\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")\n    model, tokenizer = None, None\n# --- End Model Loading ---\n\n@app.route('/summarize', methods=['POST'])\ndef summarize():\n    if not model or not tokenizer:\n        return jsonify({\"error\": \"Model is not loaded\"}), 500\n\n    # Parse JSON input\n    data = request.get_json()\n    if not data or 'dialogue' not in data:\n        return jsonify({\"error\": \"Invalid input. 'dialogue' key is required.\"}), 400\n\n    dialogue = data['dialogue']\n\n    # Format prompt using Llama 3 chat template\n    messages = [{\"role\": \"user\", \"content\": dialogue}]\n    prompt = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n\n    # Tokenize and move inputs to GPU\n    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n\n    # Generate summary\n    try:\n        with torch.no_grad():\n            outputs = model.generate(\n                input_ids=inputs[\"input_ids\"],\n                attention_mask=(inputs[\"input_ids\"] != tokenizer.pad_token_id).to(torch.long),\n                max_new_tokens=512,\n                eos_token_id=tokenizer.eos_token_id,\n                pad_token_id=tokenizer.pad_token_id\n            )\n\n        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n        # Extract assistant response\n        summary = generated_text[0].split(\"assistant\\n\")[-1].strip()\n\n        return jsonify({\"summary\": summary})\n\n    except Exception as e:\n        return jsonify({\"error\": f\"Error during generation: {str(e)}\"}), 500\n\nif __name__ == '__main__':\n    # For production, use a WSGI server like Gunicorn; port 7860 is default for HF Spaces\n    app.run(host='0.0.0.0', port=7860)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile requirements.txt\n\n# Cell 14\n\n# Flask for creating API\nflask==2.3.3\n\n# Gunicorn for production deployment\ngunicorn==21.2.0\n\n# PyTorch (CPU/GPU) compatible with Unsloth\ntorch==2.3.0\n\n# Unsloth library for Gemma models (install from GitHub)\nunsloth @ git+https://github.com/unslothai/unsloth.git\n\n# Hugging Face Transformers library\ntransformers==4.41.2\n\n# PEFT library for LoRA/parameter-efficient fine-tuning\npeft==0.11.1\n\n# Accelerate for distributed and memory-efficient training\naccelerate==0.30.1\n\n# BitsAndBytes for quantization\nbitsandbytes==0.43.1\n\n# TRL for instruction fine-tuning\ntrl==0.8.6","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile Dockerfile\n\n# Cell 15: Dockerfile\n\n# Use an official Python runtime as a parent image\nFROM python:3.10-slim\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Install system dependencies needed for pip and Git installs\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    git \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Copy the requirements file into the container\nCOPY requirements.txt .\n\n# Install Python dependencies\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy the rest of the application code into the container\nCOPY . .\n\n# Expose the port the Flask app runs on (default for Hugging Face Spaces is 7860)\nEXPOSE 7860\n\n# Command to run the application using Gunicorn\n# Gunicorn is a production-ready WSGI server\nCMD [\"gunicorn\", \"--workers\", \"1\", \"--threads\", \"4\", \"--bind\", \"0.0.0.0:7860\", \"app:app\"]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 16 Readme.md\n\n---\ntitle: Gemma 2B Medical SOAP Summarizer\nemoji: ü©∫\ncolorFrom: blue\ncolorTo: green\nsdk: docker\napp_port: 7860\npinned: false\n---\n\n# Gemma 2B Medical Dialogue Summarizer API\n\nThis Hugging Face Space hosts a **Flask API** that converts medical dialogues into **SOAP notes** (Subjective, Objective, Assessment, Plan) using a fine-tuned **Gemma 2B model**. The model is optimized with **Unsloth** for memory-efficient inference and fast response times.\n\n---\n\n## Features\n\n- Converts free-text medical dialogues into structured SOAP notes.\n- Fine-tuned on the `omi-health/medical-dialogue-to-soap-summary` dataset.\n- Uses **LoRA-based instruction fine-tuning** for efficient parameter optimization.\n- Memory- and computation-efficient with **4-bit quantization** for deployment on limited resources.\n- Ready-to-deploy Flask API with **POST endpoint** for integration into other applications.\n\n---\n\n## API Usage\n\n### Endpoint\n\n\n### Request Body\n\nSend a JSON payload containing the `dialogue` field:\n\n```json\n{\n  \"dialogue\": \"Doctor: Hello, what brings you in today? Patient: I have had a persistent cough for three days and a fever.\"\n}\n\n{\n  \"summary\": \"S: Patient reports a persistent cough and fever for three days. O: ... A: ... P: ...\"\n}\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"---\n### **Cell 17: Final Deployment Instructions**\n\n**Explanation:**  \nThis final cell summarizes the project and provides clear, step-by-step instructions for deploying the Flask API with the fine-tuned Gemma 2B model to **Hugging Face Spaces**. It guides you through creating a new Space, adding your project files, and pushing them to trigger the automated build and deployment process. This completes the end-to-end implementation of the project.\n\n```python\n# This is a text cell, not executable code.\nprint(\"\"\"\n================================================================================\n====== DEPLOYMENT INSTRUCTIONS FOR HUGGING FACE SPACES =======================\n================================================================================\n\nYou have successfully created all the necessary files for deployment. Follow these steps:\n\n1. **Create a Hugging Face Space**\n   * Visit: https://huggingface.co/new-space\n   * Enter a name (e.g., 'medical-summarizer-api')\n   * Select 'Docker' as the SDK and choose the 'Blank' template\n   * Set visibility to 'Public'\n   * Click 'Create Space'\n\n2. **Download Your Project Files**\n   * From your Colab file explorer or local project folder, ensure you have:\n     - `app.py`\n     - `requirements.txt`\n     - `Dockerfile`\n     - `README.md`\n     - `lora_model/` directory (containing fine-tuned adapters)\n   * Save them to a local directory on your computer\n\n3. **Clone the Space Repository**\n   * On your Hugging Face Space page, copy the `git clone` command\n   * In a terminal, navigate to your desired directory and run:\n     ```bash\n     git clone https://huggingface.co/spaces/<your-username>/<your-space-name>\n     ```\n\n4. **Add Your Files to the Repository**\n   * Move all downloaded files and the `lora_model` folder into the cloned repository folder\n\n5. **Commit and Push Your Changes**\n   * Navigate into the repository folder:\n     ```bash\n     cd <your-space-name>\n     ```\n   * Add, commit, and push your files:\n     ```bash\n     git add .\n     git commit -m \"Initial commit: Add fine-tuned model and Flask API\"\n     git push\n     ```\n\n6. **Monitor the Build**\n   * Return to your Hugging Face Space page\n   * The status will change to 'Building' while dependencies are installed\n   * Once complete, the status will change to 'Running' and your API will be live!\n\n7. **Test Your API**\n   * Use the example `curl` command in `README.md` or any HTTP client to verify functionality\n\n================================================================================\n\"\"\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}